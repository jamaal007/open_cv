{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Image\n",
    "### **1- Image:** \n",
    "In Python OpenCV, an image is defined as a 3-dimensional NumPy array (ndarray) representing the pixel values of the image.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "- The array has shape (height, width, channels), where:\n",
    "    - height is the number of rows (pixels) in the image.\n",
    "    - width is the number of columns (pixels) in the image.\n",
    "    - channels is the number of color channels in the image (typically 3 for RGB images, 4 for RGBA images with an alpha channel).\n",
    "- Each pixel is represented by a tuple of values (e.g., (R, G, B) for an RGB image), where each value ranges from 0 to 255 (inclusive).\n",
    "\n",
    "For example, a 640x480 RGB image would be represented as a NumPy array with shape (480, 640, 3), where each pixel is a tuple of three values (R, G, B).\n",
    "\n",
    "In OpenCV, images can be read, manipulated, and displayed using various functions, such as cv2.imread(), cv2.imshow(), and cv2.imwrite().\n",
    "\n",
    "### **2-write down the types of images:** \n",
    "Here are the common types of images:\n",
    "\n",
    "1. RGB (Red, Green, Blue): Color images with 3 channels (R, G, B).\n",
    "2. RGBA (Red, Green, Blue, Alpha): Color images with 4 channels (R, G, B, A), including an alpha channel for transparency.\n",
    "3. Grayscale: Black and white images with 1 channel (intensity).\n",
    "4. Binary: Black and white images with 1 channel (0 or 255).\n",
    "5. Indexed Color: Images with a limited palette of colors, stored as an index into a color table.\n",
    "6. CMYK (Cyan, Magenta, Yellow, Black): Color images used in printing, with 4 channels (C, M, Y, K).\n",
    "7. YUV (Luminance and Chrominance): Color images with 3 channels (Y, U, V), used in video encoding.\n",
    "8. HSV (Hue, Saturation, Value): Color images with 3 channels (H, S, V), representing color in a more intuitive way.\n",
    "9. Depth Image: Images representing depth information, often used in computer vision and robotics.\n",
    "10. Hyperspectral Image: Images with a large number of channels, each representing a specific wavelength of light.\n",
    "\n",
    "These types of images can be used in various applications, such as computer vision, graphics, printing, and more.\n",
    "\n",
    "### **3-BIT:** \n",
    "A BIT is a unit of information in computing and digital communications. It represents a single binary digit that can have only two values:\n",
    "\n",
    "- 0 (zero)\n",
    "- 1 (one)\n",
    "\n",
    "A bit is the basic building block of binary code, which is used to represent information in computers. It's the smallest unit of information that can be stored or transmitted.\n",
    "\n",
    "In terms of image processing, bits are used to represent the color depth or pixel depth of an image. For example:\n",
    "\n",
    "- 1-bit images are black and white (2 colors)\n",
    "- 4-bit images have 16 colors\n",
    "- 8-bit images have 256 colors (typical for grayscale images)\n",
    "- 24-bit images have 16,777,216 colors (true color images)\n",
    "\n",
    "The more bits used to represent an image, the more colors and detail it can contain.\n",
    "\n",
    "### **4- BIT Depth:** \n",
    "Bit depth, also known as color depth or pixel depth, refers to the number of bits used to represent the color or intensity of a single pixel in a digital image.\n",
    "\n",
    "Here are some common bit depths:\n",
    "\n",
    "- 1-bit: Black and white (2 colors)\n",
    "- 4-bit: 16 colors\n",
    "- 8-bit: 256 colors (grayscale) or 16,777,216 colors (true color)\n",
    "- 16-bit: 65,536 colors (high color)\n",
    "- 24-bit: 16,777,216 colors (true color)\n",
    "- 32-bit: 4,294,967,296 colors (deep color)\n",
    "- 48-bit: 281,474,976,710,656 colors (very deep color)\n",
    "- 64-bit: 18,446,744,073,709,551,616 colors (extremely deep color)\n",
    "\n",
    "A higher bit depth means more colors and a more detailed representation of the image. It also increases the file size and memory requirements.\n",
    "\n",
    "In image processing, bit depth is important for:\n",
    "\n",
    "- Color accuracy\n",
    "- Gradient smoothness\n",
    "- Shadow and highlight detail\n",
    "- Printing and publishing\n",
    "\n",
    "Note that bit depth is not the same as image resolution, which refers to the number of pixels in the image.\n",
    "\n",
    "\n",
    "### **5-Bitonal Image:** \n",
    "A bitonal image is a digital image that uses only two colors or shades, typically black and white. It is a binary image where each pixel is either:\n",
    "\n",
    "- 0 (black)\n",
    "- 1 (white)\n",
    "\n",
    "Bitonal images are often used in applications where only two colors are needed, such as:\n",
    "\n",
    "- Black and white printing\n",
    "- Fax transmission\n",
    "- Document scanning\n",
    "- Barcode recognition\n",
    "- Optical Character Recognition (OCR)\n",
    "\n",
    "Bitonal images are usually stored with a 1-bit depth, meaning each pixel is represented by a single bit (0 or 1). This results in a very compact image file size.\n",
    "\n",
    "Some common examples of bitonal images include:\n",
    "\n",
    "- Text documents\n",
    "- Line art\n",
    "- Logos\n",
    "- Icons\n",
    "- Barcode images\n",
    "\n",
    "Bitonal images can be displayed on any device that supports binary images, and they are often used in applications where color is not necessary or would increase the file size unnecessarily.\n",
    "\n",
    "### **6- Gray Image:** \n",
    "A gray image, also known as a grayscale image, is a digital image that uses only shades of gray, ranging from black (typically represented as 0) to white (typically represented as 255). Gray images do not have any color information, only intensity values.\n",
    "\n",
    "In a gray image, each pixel is represented by a single value, usually an integer between 0 and 255, which indicates the brightness or intensity of that pixel. The higher the value, the brighter the pixel.\n",
    "\n",
    "Gray images are often used in applications where color is not necessary or would increase the file size unnecessarily, such as:\n",
    "\n",
    "- Medical imaging (e.g., X-rays, CT scans)\n",
    "- Scientific imaging (e.g., astronomy, microscopy)\n",
    "- Document scanning\n",
    "- Fax transmission\n",
    "- Black and white photography\n",
    "\n",
    "Gray images can be stored with a variety of bit depths, including:\n",
    "\n",
    "- 8-bit (256 shades of gray)\n",
    "- 16-bit (65,536 shades of gray)\n",
    "- 32-bit (4,294,967,296 shades of gray)\n",
    "\n",
    "Gray images are useful for:\n",
    "\n",
    "- Reducing file size\n",
    "- Enhancing contrast and detail\n",
    "- Improving image processing performance\n",
    "- Focusing on texture and pattern recognition\n",
    "\n",
    "Note that gray images are different from bitonal images, which only have two shades (black and white). Gray images have a range of shades, creating a more nuanced and detailed representation of the image.\n",
    "\n",
    "### **7- RGB Image:** \n",
    "An RGB image is a digital image that uses the RGB color model to represent the colors of the image. RGB stands for Red, Green, and Blue, which are the three primary colors used to create the image.\n",
    "\n",
    "In an RGB image, each pixel is represented by three values:\n",
    "\n",
    "- Red (R)\n",
    "- Green (G)\n",
    "- Blue (B)\n",
    "\n",
    "Each value ranges from 0 (minimum intensity) to 255 (maximum intensity). The combination of these three values determines the final color of the pixel.\n",
    "\n",
    "RGB images can have various bit depths, such as:\n",
    "\n",
    "- 8-bit RGB (24-bit): 256 x 256 x 256 = 16,777,216 colors\n",
    "- 16-bit RGB (48-bit): 65,536 x 65,536 x 65,536 = 281,474,976,710,656 colors\n",
    "- 32-bit RGB (96-bit): 4,294,967,296 x 4,294,967,296 x 4,294,967,296 = 18,446,744,073,709,551,616 colors\n",
    "\n",
    "RGB images are commonly used in:\n",
    "\n",
    "- Digital photography\n",
    "- Computer graphics\n",
    "- Web design\n",
    "- Printing (although CMYK is more common in printing)\n",
    "\n",
    "The advantages of RGB images include:\n",
    "\n",
    "- Wide color gamut\n",
    "- High color accuracy\n",
    "- Easy to edit and manipulate\n",
    "\n",
    "However, RGB images may not be suitable for printing, as the color model is different from the CMYK model used in printing.\n",
    "\n",
    "### **8- Tones:** \n",
    "Tones refer to the different shades or hues of a color. In the context of imaging and color theory, tones can refer to:\n",
    "\n",
    "1. Color tones: Different shades of a color, such as light blue, sky blue, and navy blue.\n",
    "2. Grayscale tones: Different shades of gray, ranging from black to white.\n",
    "3. Skin tones: The range of colors that represent human skin, from pale to dark.\n",
    "4. Sepia tones: A warm, brownish-gray color, often used in vintage photography.\n",
    "5. Pastel tones: Soft, pale colors, often used in design and art.\n",
    "\n",
    "Tones can be used to:\n",
    "\n",
    "1. Add depth and dimension to an image\n",
    "2. Create mood and atmosphere\n",
    "3. Enhance contrast and visual interest\n",
    "4. Represent different textures and materials\n",
    "5. Create a specific aesthetic or style\n",
    "\n",
    "In image editing and color grading, tones can be adjusted using various tools and techniques, such as:\n",
    "\n",
    "1. Levels and curves\n",
    "2. Color balance and grading\n",
    "3. Exposure and contrast adjustments\n",
    "4. Color filters and overlays\n",
    "5. Toning and tinting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Reading an Image and Displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the image \n",
    "\n",
    "# import libraries\n",
    "import numpy as np \n",
    "import cv2 as cv\n",
    "\n",
    "# read image\n",
    "img=cv.imread(\"Capture.PNG\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image\n",
    "cv.imshow(\"Origninal Image\", img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hands on Practice\n",
    "import numpy as np \n",
    "import cv2 as cv\n",
    "\n",
    "# read image\n",
    "img=cv.imread(\"Capture.PNG\") \n",
    "cv.imshow(\"pheli image\", img)\n",
    "\n",
    "cv.waitKey(0)    # 0 is forever show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Resizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 as cv\n",
    "\n",
    "# read image\n",
    "img=cv.imread(\"Capture.PNG\") \n",
    "img1=cv.resize(img, (800,600))     # (800,600) is the size of new image\n",
    "\n",
    "cv.imshow(\"pheli image\", img)      # pheli image display\n",
    "cv.imshow(\"dosri image\", img1)     # Dosri image display\n",
    "\n",
    "cv.waitKey(0)    # 0 is forever show   \n",
    "cv.destroyAllWindows()   # closing all image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Converting to Gray Scale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np \n",
    "import cv2 as cv\n",
    "\n",
    "# reading and resizing image\n",
    "img=cv.imread(\"Capture.PNG\") \n",
    "img=cv.resize(img, (800,600))     # (800,600) is the size of new image\n",
    "\n",
    "# CONVERSION \n",
    "gray_img=cv.cvtColor(img1, cv.COLOR_BGR2GRAY) \n",
    "\n",
    "# Displaying \n",
    "cv.imshow(\"pheli Iage\", img)\n",
    "cv.imshow(\"Gray image\", gray_img)      # pheli image display\n",
    "\n",
    "# delay code\n",
    "cv.waitKey(0)    # 0 is forever show   \n",
    "cv.destroyAllWindows()   # closing all image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Image to black and White "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img=cv.imread(\"Capture.PNG\") \n",
    "gray_img=cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# (thresh, b_w)= cv.threshold(gray_img,127,155, cv.THRESH_BINARY)     or\n",
    "(thresh, binary)= cv.threshold(gray_img,127,155, cv.THRESH_BINARY) \n",
    "\n",
    "# Displaying \n",
    "cv.imshow(\"Original Image\", img)\n",
    "cv.imshow(\"Gray Image\", gray_img)\n",
    "cv.imshow(\"Binary Image\", binary)\n",
    "\n",
    "# delay code\n",
    "cv.waitKey(0)    # 0 is forever show   \n",
    "cv.destroyAllWindows()   # closing all image\n",
    "\n",
    "# press q to close the windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Saving or writing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from cv2 import imwrite\n",
    "\n",
    "# reading and converting image\n",
    "img=cv.imread(\"Capture.PNG\") \n",
    "gray_img=cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# saving the image\n",
    "imwrite(\"screen.png\", gray_img)\n",
    "\n",
    "# you can see the image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Basic funstions and manipulations in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "img=cv.imread(\"Capture.PNG\")\n",
    "\n",
    "# 1- resize\n",
    "resize_img=cv.resize(img, (450, 250))  # width and Heigth\n",
    "\n",
    "# 2- gray Image\n",
    "gray_img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# 3- Black and white image\n",
    "(thresh, binary)= cv.threshold(img,127,155, cv.THRESH_BINARY) \n",
    "\n",
    "# 4- Blurred Image\n",
    "blurr_img=cv.GaussianBlur(img, (7,7), 0)    # (7,7) is kernel size and it must be number always. and zero sigma google it\n",
    "# kernel size is matrix represents intensity. \n",
    "\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Resized\", resize_img)\n",
    "cv.imshow(\"Black and White\", binary)\n",
    "cv.imshow(\"Gray Image\", gray_img)\n",
    "cv.imshow(\"Blurred Image\", blurr_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- Edge Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "img=cv.imread(\"Capture.PNG\")\n",
    "\n",
    "# 6- edge detection \n",
    "edge_img=cv.Canny(img, 47,47)\n",
    "\n",
    "# # 7- a- Modification of thickness of lines\n",
    "# dilated_img=cv.dilate(edge_img, (23,23),iterations=1)\n",
    "\n",
    "\n",
    "# 7- b- Modification of thickness of lines\n",
    "mat_kernel=np.ones((7,7), np.uint8)\n",
    "dilated_img=cv.dilate(edge_img, (mat_kernel),iterations=1)    # dilation mean thickness of edge lines \n",
    "\n",
    "# 8- make thinner lines of edges \n",
    "erude_img=cv.erode(dilated_img, mat_kernel, iterations=1)\n",
    "\n",
    "\n",
    "cv.imshow(\"Detected Edges\", edge_img)\n",
    "cv.imshow(\"Dilated Image\", dilated_img)\n",
    "cv.imshow(\"Eroded Image\", erude_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Cropping the Image, we will use numpy not OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of original image array: (768, 773, 3)\n",
      "Dimension of resized image array: (250, 450, 3)\n",
      "Dimension of Cropped Image: (200, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# before going to cropping printing the dimensions of images  \n",
    "import cv2 as cv \n",
    "import numpy as np \n",
    "\n",
    "# 1- original image\n",
    "img=cv.imread(\"Capture.PNG\")\n",
    "\n",
    "# 2- resize image\n",
    "resize_img=cv.resize(img, (450, 250))  # width and Heigth\n",
    "\n",
    "# 3- cropping image\n",
    "crop_img=resize_img[0:200, 200:300]    # [Height, width] from: to...\n",
    "\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Resized\", resize_img)\n",
    "cv.imshow(\"Crpped Image\", crop_img)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"Dimension of original image array:\", img.shape)\n",
    "print(\"Dimension of resized image array:\", resize_img.shape)\n",
    "print(\"Dimension of Cropped Image:\",crop_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9- Joining two images (To look them side by side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining two images\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# reading image from folder\n",
    "img=cv.imread(\"resources/image1.jpg\")\n",
    "\n",
    "# stacking same image\n",
    "# 1- horizontal stack\n",
    "hor_stk=np.hstack((img,img))\n",
    "\n",
    "# 2- vertical stacking \n",
    "ver_stk=np.vstack((img,img))\n",
    "\n",
    "\n",
    "\n",
    "# Showing image\n",
    "cv.imshow(\"Horizontal Stacking:\", hor_stk)\n",
    "cv.imshow(\"Vertical Stacking:\", ver_stk)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can only stacking images with same shape (width, heigth and color channel--> (600,500,3)). \n",
    "\n",
    "- We can not resize the stack image we have to define a function for that. \n",
    "\n",
    "- same number of channel are must. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a Python function that uses OpenCV to stack multiple images of different sizes: \n",
    "\n",
    "This stacking function needs understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def stack_images(images, axis=0):\n",
    "    \"\"\"\n",
    "    Stack multiple images of different sizes along a specified axis.\n",
    "\n",
    "    Args:\n",
    "        images (list): List of images to stack\n",
    "        axis (int): Axis to stack along (0 for horizontal, 1 for vertical)\n",
    "\n",
    "    Returns:\n",
    "        stacked_image (numpy array): Stacked image\n",
    "    \"\"\"\n",
    "    # Get the maximum width and height of the images\n",
    "    max_width = max(img.shape[1] for img in images)\n",
    "    max_height = max(img.shape[0] for img in images)\n",
    "\n",
    "    # Create a blank image with the maximum width and height\n",
    "    stacked_image = np.zeros((max_height, max_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Stack the images\n",
    "    for i, img in enumerate(images):\n",
    "        h, w, _ = img.shape\n",
    "        if axis == 0:  # Horizontal stacking\n",
    "            stacked_image[:h, i * w:(i + 1) * w, :] = img\n",
    "        elif axis == 1:  # Vertical stacking\n",
    "            stacked_image[i * h:(i + 1) * h, :w, :] = img\n",
    "\n",
    "    return stacked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an explanation of the code:\n",
    "\n",
    "1. We first get the maximum width and height of the input images using list comprehensions.\n",
    "2. We create a blank image with the maximum width and height using NumPy.\n",
    "3. We iterate through the input images and stack them along the specified axis (0 for horizontal, 1 for vertical).\n",
    "4. We use NumPy slicing to copy each image into the stacked image array.\n",
    "5. Finally, we return the stacked image.\n",
    "\n",
    "You can use this function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [cv.imread('image1.jpg'), cv.imread('image2.jpg'), cv.imread('image3.jpg')]\n",
    "stacked_image = stack_images(images, axis=0)  # Horizontal stacking\n",
    "\n",
    "\n",
    "\n",
    "cv.imshow('Stacked Image', stacked_image)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10- How to change the perspective of an image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 195, 3)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# reading image from folder\n",
    "img=cv.imread(\"resources/warp.jpeg\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# reading image from folder\n",
    "img=cv.imread(\"resources/warp.jpeg\")\n",
    "\n",
    "# defining points  1 (How we can get it: check the next topic \"Coordinate of an image\")\n",
    "point1=np.float32([[21,112],[171,116],[128,41],[58,45]])\n",
    "width=195\n",
    "height=220\n",
    "# or \n",
    "# width, height= 195,220\n",
    "\n",
    "# defining point 2\n",
    "point2=np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "\n",
    "# defining matrix\n",
    "matrix=cv.getPerspectiveTransform(point1,point2)\n",
    "# out_img=cv.warpPerspectiveT(img,matrix,(width,height))\n",
    "out_img=cv.warpPerspective(img, matrix, (width,height))\n",
    "# resize the out image\n",
    "# out_img=cv.resize(img, (450, 250))  # width and Heigth\n",
    "\n",
    "cv.imshow(\"Original Image:\", img)\n",
    "cv.imshow(\"Prespected or Transformed Image:\", out_img)\n",
    "\n",
    "# writing image\n",
    "cv.imwrite(\"resources/prespected.jpeg\", out_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11- \n",
    " - Coordinates of image \n",
    " - BGR Color codes fro an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# defining a function\n",
    "def find_cood(event, x,y,flags, params):\n",
    "    if event==cv.EVENT_LBUTTONDOWN:\n",
    "        # left mouse click\n",
    "        print(x,\"\", y)\n",
    "        # how to define or print on the same image or window\n",
    "        font=cv.FONT_HERSHEY_PLAIN\n",
    "        cv.putText(img,str(x) + \",\" + str(y),(x,y),font,1,(255,0,179),thickness=2)\n",
    "        # show the text on image and img itself\n",
    "        cv.imshow(\"Image\",img)\n",
    "    \n",
    "    # for color finding\n",
    "    if event==cv.EVENT_RBUTTONDOWN:\n",
    "        print(x,\"\",y)\n",
    "        \n",
    "        font=cv.FONT_HERSHEY_SIMPLEX\n",
    "        b=img[y,x,0]\n",
    "        g=img[y,x,1]\n",
    "        r=img[y,x,2]\n",
    "        \n",
    "        cv.putText(img,str(b)+\",\"+ str(g) + \",\" + str(r) , (x,y), font, 1, (255,897,0),2)\n",
    "        cv.imshow(\"Image\",img)\n",
    "\n",
    "# final function to read and display\n",
    "if __name__ == \"__main__\":\n",
    "    # reading an image\n",
    "    img=cv.imread(\"resources/warp.jpeg\",1)\n",
    "    # display an image\n",
    "    cv.imshow(\"Image\",img)\n",
    "    # setting call back function \n",
    "    cv.setMouseCallback(\"Image\", find_cood)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12- Object Selection Based On color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# reading image\n",
    "img=cv.imread(\"resources/image2.jpg\") # here we need to change the image rest the following code will remain the same \n",
    "\n",
    "# convert to hsv (Hue, saturation and value)\n",
    "hsv_img=cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# sliders making\n",
    "def slider():\n",
    "    pass\n",
    "\n",
    "path=\"resources/image2.jpg\"\n",
    "\n",
    "cv.namedWindow(\"Bars\")\n",
    "cv.resizeWindow(\"Bars\",900,300)\n",
    "\n",
    "cv.createTrackbar(\"Hue Min\",\"Bars\",0,179,slider)\n",
    "cv.createTrackbar(\"Hue Max\",\"Bars\",179,179,slider)\n",
    "cv.createTrackbar(\"Sat Min\",\"Bars\",0,255,slider)\n",
    "cv.createTrackbar(\"Sat Max\",\"Bars\",255,255,slider)\n",
    "cv.createTrackbar(\"Val Min\",\"Bars\",0,255,slider)\n",
    "cv.createTrackbar(\"Val Max\",\"Bars\",255,255,slider)\n",
    "\n",
    "\n",
    "img=cv.imread(path)\n",
    "hsv_img=cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# hue_min=cv.getTrackbarPos(\"Hue Min\", \"Bars\")\n",
    "# print(hue_min)\n",
    "\n",
    "\n",
    "# while loop\n",
    "while True:\n",
    "    img=cv.imread(path)\n",
    "    hsv_img=cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    hue_min=cv.getTrackbarPos(\"Hue Min\", \"Bars\")\n",
    "    hue_max=cv.getTrackbarPos(\"Hue Max\", \"Bars\")\n",
    "    sat_min=cv.getTrackbarPos(\"Sat Min\", \"Bars\")\n",
    "    sat_max=cv.getTrackbarPos(\"Sat Max\", \"Bars\")\n",
    "    val_min=cv.getTrackbarPos(\"Val Min\", \"Bars\")\n",
    "    val_max=cv.getTrackbarPos(\"Val Max\", \"Bars\")\n",
    "    print(hue_min, hue_max,sat_min,sat_max,val_min,val_max)\n",
    "    \n",
    "    # to these changes inside the image\n",
    "    lower=np.array([hue_min, sat_min, val_min])\n",
    "    upper=np.array([hue_max, sat_max, val_max])\n",
    "    \n",
    "    mask_img=cv.inRange(hsv_img,lower,upper)\n",
    "    out_img=cv.bitwise_and(img, img, mask=mask_image)\n",
    "    \n",
    "    cv.imshow(\"Original\", img)\n",
    "    cv.imshow(\"HSV Image\", hsv_img)\n",
    "    cv.imshow(\"Mask\", mask_img)\n",
    "    cv.imshow(\"Final Image\",out_img)\n",
    "    if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13- Face Detection in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2 as cv\n",
    "\n",
    "face_cascade=cv.CascadeClassifier(\"resources/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "img=cv.imread(resources/image3.jpg)\n",
    "# cv.resize(img, (value, value))\n",
    "\n",
    "# making gray image\n",
    "gray_img=cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# face detected in gray image\n",
    "faces=face_cascade.detectMultiScale(gray_img, 1.1,4)\n",
    "\n",
    "# draw a rectangle around the face\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(img, (x,y), (x+y, y+h), (255,0,0), 2)\n",
    "\n",
    "# show the detected face and save\n",
    "cv.imshow(\"face Detected, img\")\n",
    "cv.imwrite(\"resources/Detected Faces.png\", img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- download faces image and try for this code\n",
    "# 2- haarcascade_frontalface_default.xml     ===>  downloading this "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
